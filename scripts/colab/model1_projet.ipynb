{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3zig20yJwub8"
      },
      "source": [
        "# Premier entrainement sur les données FR et AR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2o2Gzif7yPhl"
      },
      "source": [
        "### Importation des données"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDoTvUw5wGDn",
        "outputId": "124a2013-05e7-421a-9317-69c0e38036ef"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "list_train = glob.glob(\"/content/drive/MyDrive/MASTER_2_TAL-IM/CNN/corpus-traintest/train/*/*\")\n",
        "print(list_train)\n",
        "\n",
        "list_test = glob.glob(\"/content/drive/MyDrive/MASTER_2_TAL-IM/CNN/corpus-traintest/test/*/*\")\n",
        "print(list_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_72gfiD0zvFM"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "dico = {'fr' : 0, 'ar' : 1} # il va permettre de faire la correspondance\n",
        "\n",
        "# taille des images\n",
        "img_rows = 28\n",
        "img_cols = 28"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nd8k3Gqaz5Bq"
      },
      "outputs": [],
      "source": [
        "# Listes pour le train\n",
        "x_train = [] # va contenir les images\n",
        "y_train = [] # va contenir les labels\n",
        "\n",
        "# boucle qui va permettre de parcourir toutes ces valeurs et récupérer à chaque fois l'image\n",
        "# la lire, la remettre en format 28-28 et la classer en nasale ou non nasale\n",
        "for path in list_train :\n",
        "  x = cv2.imread(path,0).astype(np.uint8) # lire l'image en un format economique\n",
        "  x = cv2.resize(x, (img_rows, img_cols)) # remettre à la bonne taille\n",
        "  nasalite = path.split('/')[-2]  # récupérer le contenu 2 slash / avant la fin du chemin\n",
        "  y = dico[nasalite]  # on forme le dico\n",
        "  x_train.append(x)\n",
        "  y_train.append(y)\n",
        "\n",
        "print(len(x_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhHnWrmE0b5W",
        "outputId": "9aacbf37-a28f-4d5e-e294-01e5ff5fc1ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23\n"
          ]
        }
      ],
      "source": [
        "# Listes pour le test\n",
        "x_test = [] # va contenir les images\n",
        "y_test = [] # va contenir les labels\n",
        "\n",
        "for path in list_test :\n",
        "  x = cv2.imread(path,0).astype(np.uint8) # lire l'image en un format economique\n",
        "  x = cv2.resize(x, (img_rows, img_cols)) # remettre à la bonne taille\n",
        "  nasalite = path.split('/')[-2]  # récupérer le contenu 2 slash / avant la fin du chemin\n",
        "  y = dico[nasalite]  # on forme le dico\n",
        "  x_test.append(x)\n",
        "  y_test.append(y)\n",
        "\n",
        "print(len(x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FPjQsej10lpl"
      },
      "outputs": [],
      "source": [
        "# Importations des librairies et modules\n",
        "from __future__ import print_function\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adadelta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-TsMwrV0vD6",
        "outputId": "1bbbd7a8-5533-44af-d37b-e9d8b950b8f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1. 0.]\n",
            "[1. 0.]\n",
            "4\n",
            "(217, 28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "# Définition des paramétres\n",
        "batch_size = 12\n",
        "num_classes = 2\n",
        "epochs = 20\n",
        "\n",
        "# Convertire en np.array\n",
        "x_train_array = np.array(x_train)\n",
        "x_test_array = np.array(x_test)\n",
        "\n",
        "x_train_array_reshaped = x_train_array.reshape(-1, img_rows,img_cols,1) # -1 il va de lui même récupérer la valeur de x_train\n",
        "x_test_array_reshaped = x_test_array.reshape(-1, img_rows,img_cols,1)\n",
        "input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train_ok = x_train_array_reshaped.astype('float32') / 255\n",
        "x_test_ok = x_test_array_reshaped.astype('float32') / 255\n",
        "\n",
        "y_train_ok = to_categorical(y_train)\n",
        "print(y_train_ok[0])\n",
        "\n",
        "y_test_ok = to_categorical(y_test)\n",
        "print(y_test_ok[0])\n",
        "\n",
        "print(x_train_ok.ndim)\n",
        "print(x_train_ok.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlbZe4uj03hD",
        "outputId": "cb4b57d7-3482-4c5f-bf07-e752a59456a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "19/19 [==============================] - 2s 51ms/step - loss: 0.7077 - accuracy: 0.5300 - val_loss: 0.6821 - val_accuracy: 0.7391\n",
            "Epoch 2/20\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.6609 - accuracy: 0.6267 - val_loss: 0.7381 - val_accuracy: 0.5217\n",
            "Epoch 3/20\n",
            "19/19 [==============================] - 1s 42ms/step - loss: 0.6961 - accuracy: 0.6037 - val_loss: 0.6405 - val_accuracy: 0.6522\n",
            "Epoch 4/20\n",
            "19/19 [==============================] - 1s 44ms/step - loss: 0.5948 - accuracy: 0.6636 - val_loss: 0.5821 - val_accuracy: 0.6087\n",
            "Epoch 5/20\n",
            "19/19 [==============================] - 1s 59ms/step - loss: 0.5133 - accuracy: 0.7143 - val_loss: 0.5919 - val_accuracy: 0.6957\n",
            "Epoch 6/20\n",
            "19/19 [==============================] - 1s 68ms/step - loss: 0.4781 - accuracy: 0.7512 - val_loss: 0.4378 - val_accuracy: 0.7826\n",
            "Epoch 7/20\n",
            "19/19 [==============================] - 1s 64ms/step - loss: 0.3934 - accuracy: 0.8111 - val_loss: 0.4011 - val_accuracy: 0.7826\n",
            "Epoch 8/20\n",
            "19/19 [==============================] - 1s 69ms/step - loss: 0.3195 - accuracy: 0.8710 - val_loss: 0.3462 - val_accuracy: 0.8696\n",
            "Epoch 9/20\n",
            "19/19 [==============================] - 1s 68ms/step - loss: 0.2692 - accuracy: 0.9124 - val_loss: 0.3289 - val_accuracy: 0.7826\n",
            "Epoch 10/20\n",
            "19/19 [==============================] - 1s 49ms/step - loss: 0.2146 - accuracy: 0.9078 - val_loss: 0.3375 - val_accuracy: 0.8696\n",
            "Epoch 11/20\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 0.2202 - accuracy: 0.9124 - val_loss: 0.2840 - val_accuracy: 0.8261\n",
            "Epoch 12/20\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.1934 - accuracy: 0.9309 - val_loss: 0.2800 - val_accuracy: 0.8696\n",
            "Epoch 13/20\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.1639 - accuracy: 0.9355 - val_loss: 0.2746 - val_accuracy: 0.8696\n",
            "Epoch 14/20\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 0.1435 - accuracy: 0.9447 - val_loss: 0.2671 - val_accuracy: 0.8696\n",
            "Epoch 15/20\n",
            "19/19 [==============================] - 1s 38ms/step - loss: 0.1361 - accuracy: 0.9539 - val_loss: 0.2279 - val_accuracy: 0.9130\n",
            "Epoch 16/20\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.1366 - accuracy: 0.9447 - val_loss: 0.2460 - val_accuracy: 0.8696\n",
            "Epoch 17/20\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.1501 - accuracy: 0.9355 - val_loss: 0.2688 - val_accuracy: 0.8696\n",
            "Epoch 18/20\n",
            "19/19 [==============================] - 1s 39ms/step - loss: 0.1231 - accuracy: 0.9493 - val_loss: 0.2478 - val_accuracy: 0.9130\n",
            "Epoch 19/20\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.1169 - accuracy: 0.9539 - val_loss: 0.2107 - val_accuracy: 0.9130\n",
            "Epoch 20/20\n",
            "19/19 [==============================] - 1s 40ms/step - loss: 0.0928 - accuracy: 0.9677 - val_loss: 0.2111 - val_accuracy: 0.9565\n",
            "Test loss: 0.21110746264457703\n",
            "Test accuracy: 0.95652174949646\n"
          ]
        }
      ],
      "source": [
        "# Création du modéles du réseau neuronal\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# Complilation des modéles pour permettre de lancer l'entrainement\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Entraînement du modèle sur les données d'entraînement\n",
        "model.fit(x_train_ok, y_train_ok,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test_ok, y_test_ok))\n",
        "\n",
        "# Evaluation du modèle sur les données de test\n",
        "score = model.evaluate(x_test_ok, y_test_ok, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Enregistrer le meilleur model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aroYy-Rw4T2J",
        "outputId": "0c6edd29-1f1b-4b6f-c751-9943309f5ca3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "15/15 [==============================] - 3s 123ms/step - loss: 0.0748 - accuracy: 0.9711 - val_loss: 0.1450 - val_accuracy: 0.9773\n",
            "Epoch 2/20\n",
            "15/15 [==============================] - 2s 114ms/step - loss: 0.0677 - accuracy: 0.9653 - val_loss: 0.1135 - val_accuracy: 0.9773\n",
            "Epoch 3/20\n",
            "15/15 [==============================] - 1s 42ms/step - loss: 0.0533 - accuracy: 0.9711 - val_loss: 0.1619 - val_accuracy: 0.9545\n",
            "Epoch 4/20\n",
            "15/15 [==============================] - 1s 40ms/step - loss: 0.0490 - accuracy: 0.9595 - val_loss: 0.1991 - val_accuracy: 0.9091\n",
            "Epoch 5/20\n",
            "15/15 [==============================] - 1s 56ms/step - loss: 0.0541 - accuracy: 0.9711 - val_loss: 0.1892 - val_accuracy: 0.9318\n",
            "Epoch 5: early stopping\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.1536 - accuracy: 0.9130\n"
          ]
        }
      ],
      "source": [
        "# Enregistrer le meilleur modéle\n",
        "# Importation des callbacks EarlyStopping et ModelCheckpoint depuis Keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Création de l'objet EarlyStopping pour arrêter l'entraînement tôt si la perte de validation ne s'améliore pas\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
        "\n",
        "# Création de l'objet ModelCheckpoint pour sauvegarder le meilleur modèle\n",
        "# Le meilleur modèle est défini en fonction de la perte de validation ('val_loss')\n",
        "mc = ModelCheckpoint(\n",
        "    '/content/drive/MyDrive/MASTER_2_TAL-IM/CNN/Modeltest',\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)\n",
        "\n",
        "# Compilation du modèle avec la fonction de perte 'categorical_crossentropy',\n",
        "# l'optimiseur 'sgd' (descente de gradient stochastique),\n",
        "# et la métrique d'évaluation 'accuracy' (précision)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Entraînement du modèle avec les données d'entraînement\n",
        "history = model.fit(x_train_ok, y_train_ok, batch_size=batch_size, epochs=epochs, verbose=1, validation_split=0.2, callbacks=[es, mc])\n",
        "\n",
        "# Évaluation du modèle sur les données de test\n",
        "score = model.evaluate(x_test_ok, y_test_ok, verbose=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLwY5uv2AZlQ"
      },
      "source": [
        "# Evaluation du model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPIVYpU1Ah3U",
        "outputId": "4e061a73-5c92-4121-df1d-c42be881b4f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 452ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Image : 19441287_extrait2_a.png, Langue prédite : AR\n",
            "Image : 34930235_extrait6_u.png, Langue prédite : FR\n",
            "Image : 19442524_extrait3_u.png, Langue prédite : AR\n",
            "Image : 19441294_extrait3_u.png, Langue prédite : AR\n",
            "Image : 34930213_extrait1_v.png, Langue prédite : FR\n",
            "Image : 34930240_extrait12_i.png, Langue prédite : FR\n",
            "Image : 34930225_extrait2_a.png, Langue prédite : FR\n",
            "Image : 19441294_extrait9_i:.png, Langue prédite : AR\n",
            "Image : 19441272_extrait3_a:.png, Langue prédite : AR\n",
            "Image : 34930215_extrait2_a.png, Langue prédite : FR\n"
          ]
        }
      ],
      "source": [
        "from keras.models import load_model\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Charger le meilleur modèle\n",
        "best_model = load_model('/content/drive/MyDrive/MASTER_2_TAL-IM/CNN/Modeltest')\n",
        "\n",
        "# Dossier contenant les images mélangées\n",
        "folder_path = \"/content/drive/MyDrive/MASTER_2_TAL-IM/CNN/corpus-melange\"\n",
        "\n",
        "# Liste pour stocker les résultats\n",
        "predictions = []\n",
        "\n",
        "# taille des images\n",
        "img_rows = 28\n",
        "img_cols = 28\n",
        "\n",
        "# Parcourir toutes les images du dossier\n",
        "for filename in os.listdir(folder_path):\n",
        "    if filename.endswith(\".png\"):  # Assurez-vous que vous ne traitez que les fichiers JPEG (ajustez au besoin)\n",
        "        # Charger et prétraiter l'image\n",
        "        image_path = os.path.join(folder_path, filename)\n",
        "        img = cv2.imread(image_path, 0).astype(np.uint8)\n",
        "        img = cv2.resize(img, (img_rows, img_cols))\n",
        "        img_reshaped = img.reshape(1, img_rows, img_cols, 1)\n",
        "        img_normalized = img_reshaped.astype('float32') / 255\n",
        "\n",
        "        # Faire une prédiction avec le modèle\n",
        "        prediction = best_model.predict(img_normalized)\n",
        "        predicted_class = np.argmax(prediction)\n",
        "\n",
        "        # Ajouter le résultat à la liste\n",
        "        predictions.append((filename, predicted_class))\n",
        "\n",
        "# Afficher les résultats\n",
        "for result in predictions:\n",
        "    print(f\"Image : {result[0]}, Langue prédite : {'FR' if result[1] == 0 else 'AR'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBoc7UtCCEfZ"
      },
      "source": [
        "## Matrice de confusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "g9iUZfrbCD65",
        "outputId": "da77b181-37b5-49ed-d1f0-3f751ee0ce07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 737ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf8AAAGdCAYAAAAczXrvAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAU50lEQVR4nO3dbYyVZ5kH8OsM0sMswbOllGGIxbJag0KlCMgWFCUlNmxLype+bDCL9EN9oSDOWu0kUmyqHqtGWQSpJVFoYmtNFGzMWtMQkTTF8m40WfuSsqYxOxBWZcK0PVY4+8HsZOce+jL2Gc7Z+/n9mucDz5me5z4k5D//67nPOZVms9kMAKA0Olq9AADgwhL+AFAywh8ASkb4A0DJCH8AKBnhDwAlI/wBoGSEPwCUjPAHgJJ5U6sXAADtpnPO7YU914tHtxT2XEVpq/Av8i8bcvDi0S3x0l9avQpoP+NGO70qeQ/G8351AMAwbdX8AaAtVCqtXsGoEv4AkMp87C/8ASCVefPP+1cbAGAYzR8AUsb+AFAyxv4AQE40fwBIGfsDQMkY+wMAOdH8ASBl7A8AJWPsDwDkRPMHgJSxPwCUTOZjf+EPAKnMm3/erw4AGEbzB4BU5s1f+ANAqiPve/55/2oDAAyj+QNAytgfAEom87f65f2rDQAwjOYPACljfwAoGWN/ACAnmj8ApIz9AaBkMh/7C38ASGXe/PN+dQDAMJo/AKSM/QGgZIz9AYCcaP4AkDL2B4CSMfYHAHKi+QNAKvPmL/wBIJX5Pf+8f7UBAIbR/AEgZewPACWT+dhf+ANAKvPmn/erAwCG0fwBIGXsDwDlUsk8/I39AaBkNH8ASOTe/IU/AKTyzn5jfwAoG80fABK5j/01fwBIVCqVwo6R2LdvXyxfvjymTp0alUoldu/ePeTxZrMZd911V3R3d0dnZ2csXbo0nnnmmRG/PuEPAG1iYGAgZs+eHVu3bj3v41/5yldi8+bNcd9998WTTz4Z48ePj2uvvTZeeumlEV3H2B8AEq0a+y9btiyWLVt23seazWZs2rQpPve5z8UNN9wQEREPPPBAdHV1xe7du+OWW2553dfR/AEgUeTYv9FoRH9//5Cj0WiMeE3Hjx+Pvr6+WLp06eC5Wq0WCxYsiP3794/ouYQ/AKQqxR31ej1qtdqQo16vj3hJfX19ERHR1dU15HxXV9fgY6+XsT8AjKLe3t7o6ekZcq5arbZoNX8l/AEgUeQ9/2q1WkjYT5kyJSIiTpw4Ed3d3YPnT5w4EVddddWInsvYHwASrXqr36uZPn16TJkyJfbs2TN4rr+/P5588sm4+uqrR/Rcmj8AtIkzZ87Es88+O/jn48ePx7Fjx2LixIkxbdq0WL9+fXzhC1+IK664IqZPnx4bNmyIqVOnxooVK0Z0HeEPAIlWvdXv0KFDsWTJksE//+9egVWrVsWOHTviM5/5TAwMDMRtt90Wf/rTn+J973tfPProozFu3LgRXafSbDabha78Deicc3urlwBt5cWjW+Klv7R6FdB+xo1ydb3kXx4q7Ln++4F/Luy5iuKePwCUjLE/AKTy/l4f4Q8AKd/qBwBkRfMHgETuzV/4A0BC+ANA2eSd/e75A0DZaP4AkDD2B4CSyT38jf0BoGQ0fwBI5N78hT8AJHIPf2N/ACgZzR8AUnkXf+EPACljfwAgK5o/ACRyb/7CHwASwh8Ayibv7HfPHwDKRvMHgISxPwCUTO7hb+wPACWj+QNAIvfmL/wBICH8E6dOnYrvfOc7sX///ujr64uIiClTpsTChQvjIx/5SFx66aWFLxIAKM6I7vkfPHgw3vGOd8TmzZujVqvF4sWLY/HixVGr1WLz5s0xY8aMOHTo0Gs+T6PRiP7+/iFHo9H4m18EABSqUuDRhkbU/NeuXRs33nhj3HfffcNGIs1mMz72sY/F2rVrY//+/a/6PPV6Pe6+++4h5zZu3DiSpQDAqMl97F9pNpvN1/vDnZ2dcfTo0ZgxY8Z5H//tb38bc+bMiRdffPFVn6fRaAxr+tVqNf7+H//19S4FSuHFo1vipb+0ehXQfsaN8o61f+j598Ke67mv/1Nhz1WUEf31TZkyJQ4cOPCK4X/gwIHo6up6zeepVqtRrVZHcmkAuGByb/4jCv9Pf/rTcdttt8Xhw4fjmmuuGQz6EydOxJ49e2L79u3xta99bVQWCgAXSubZP7LwX7NmTUyaNCm+8Y1vxLe+9a04e/ZsRESMGTMm5s6dGzt27IibbrppVBYKABeK5p+4+eab4+abb46XX345Tp06FRERkyZNirFjxxa+OACgeH/zlomxY8dGd3d3kWsBgLaQefH3CX8AkMp97O+LfQCgZDR/AEhkXvyFPwCkOjryTn9jfwAoGc0fABLG/gBQMnb7AwBZ0fwBIJF58Rf+AJDKfewv/AEgkXv4u+cPACWj+QNAIvPiL/wBIGXsDwBkRfMHgETmxV/4A0DK2B8AuCDOnj0bGzZsiOnTp0dnZ2e87W1vi3vuuSeazWah19H8ASDRquJ/7733xrZt22Lnzp0xc+bMOHToUKxevTpqtVqsW7eusOsIfwBItGrs/8QTT8QNN9wQ1113XUREXH755fHQQw/FgQMHCr2OsT8AjKJGoxH9/f1Djkajcd6fXbhwYezZsyeefvrpiIj41a9+FY8//ngsW7as0DUJfwBIVCrFHfV6PWq12pCjXq+f97p33nln3HLLLTFjxowYO3ZszJkzJ9avXx8rV64s9PUZ+wNAosixf29vb/T09Aw5V61Wz/uzP/jBD+J73/tePPjggzFz5sw4duxYrF+/PqZOnRqrVq0qbE3CHwASRd7yr1arrxj2qTvuuGOw/UdEXHnllfG73/0u6vV6oeFv7A8AbeKFF16Ijo6h0TxmzJg4d+5codfR/AEg0ard/suXL48vfvGLMW3atJg5c2YcPXo0vv71r8ett95a6HWEPwAkWvU+/29+85uxYcOG+MQnPhEnT56MqVOnxkc/+tG46667Cr2O8AeANjFhwoTYtGlTbNq0aVSvI/wBIJH7Z/sLfwBIZJ79dvsDQNlo/gCQMPYHgJLJPfyN/QGgZDR/AEhkXvyFPwCkch/7C38ASGSe/e75A0DZaP4AkDD2B4CSyTz7jf0BoGw0fwBIdGRe/YU/ACQyz35jfwAoG80fABJ2+wNAyXTknf3CHwBSuTd/9/wBoGQ0fwBIZF78hT8ApCqRd/ob+wNAyWj+AJCw2x8ASsZufwAgK5o/ACQyL/7CHwBSuX+rn7E/AJSM5g8AicyLv/AHgFTuu/2FPwAkMs9+9/wBoGw0fwBI5L7bX/gDQCLv6Df2B4DS0fwBIGG3PwCUTO7f6mfsDwAlo/kDQMLYHwBKJvPsN/YHgLLR/AEgYewPACWT+25/4Q8Aidybv3v+AFAymj8AJPLu/cIfAIbJ/Vv9jP0BoGQ0fwBIZF78hT8ApOz2BwCyIvwBIFGpFHeM1O9///v48Ic/HJdcckl0dnbGlVdeGYcOHSr09Rn7A0CiVbv9//jHP8aiRYtiyZIl8dOf/jQuvfTSeOaZZ+Liiy8u9DrCHwDaxL333huXXXZZfPe73x08N3369MKvY+wPAIlWjf0feeSRmDdvXtx4440xefLkmDNnTmzfvr3w1yf8ASBRqVQKOxqNRvT39w85Go3Gea/73HPPxbZt2+KKK66In/3sZ/Hxj3881q1bFzt37iz29TWbzWahzwgA/8+t3fUfhT3XJb96OO6+++4h5zZu3Bif//znh/3sRRddFPPmzYsnnnhi8Ny6devi4MGDsX///sLW1Fb3/H/7Xy+0egnQVmZ0/11c/smftHoZ0Hb+89+ub/USXrfe3t7o6ekZcq5arZ73Z7u7u+Nd73rXkHPvfOc744c//GGha2qr8AeAdlDkh/xUq9VXDPvUokWL4qmnnhpy7umnn463vvWtha0nQvgDwDAdLfqAv0996lOxcOHC+NKXvhQ33XRTHDhwIO6///64//77C72ODX8A0Cbmz58fu3btioceeihmzZoV99xzT2zatClWrlxZ6HU0fwBItKr5R0Rcf/31cf31o7unQfgDQMIX+wAAWdH8ASDRyrH/hSD8ASCR+dTf2B8AykbzB4BEq77S90IR/gCQyH0sLvwBIJF58c/+lxsAIKH5A0DCPX8AKJnMs9/YHwDKRvMHgIRP+AOAksn9nr+xPwCUjOYPAInMi7/wB4BU7vf8jf0BoGQ0fwBIVCLv6i/8ASCR+9hf+ANAIvfwd88fAEpG8weARCXz9/oJfwBIGPsDAFnR/AEgkfnUX/gDQMoX+wAAWdH8ASCR+4Y/4Q8Aicyn/sb+AFA2mj8AJDp8sQ8AlEvuY3/hDwCJ3Df8uecPACWj+QNAIvcP+RH+AJDIPPuN/QGgbDR/AEgY+wNAyWSe/cb+AFA2mj8AJHJvxsIfABKVzOf+uf9yAwAkNH8ASOTd+4U/AAzjrX4AUDJ5R797/gBQOpo/ACQyn/oLfwBIeasfAJAVzR8AErk3Y+EPAAljfwDggvvyl78clUol1q9fX/hza/4AkGh17z948GB8+9vfjne/+92j8vyaPwAkKpVKYcdInTlzJlauXBnbt2+Piy++eBRenfAHgFHVaDSiv79/yNFoNF7x59esWRPXXXddLF26dNTWJPwBINFR4FGv16NWqw056vX6ea/7/e9/P44cOfKKjxfFPX8ASBS527+3tzd6enqGnKtWq8N+7vnnn49PfvKT8dhjj8W4ceMKu/75CH8ASBS54a9arZ437FOHDx+OkydPxnve857Bc2fPno19+/bFli1botFoxJgxYwpZk/AHgDZwzTXXxK9//esh51avXh0zZsyIz372s4UFf4TwB4BhWvEZPxMmTIhZs2YNOTd+/Pi45JJLhp1/o4Q/ACQ6Wv5O/9El/AGgTe3du3dUnlf4A0Ai84/2F/4AkKpkPvb3IT8AUDKaPwAkjP0BoGRy3+1v7A8AJaP5A0DC2B8ASkb4A0DJeKsfAJAVzR8AEh15F3/hDwApY38AICuaPwAk7PYHgJIx9gcAsqL5A0DCbn8AKBljfwAgK5o/ACTs9geAksk8+4U/AKQ6Mq/+hd/zf/755+PWW2991Z9pNBrR398/5Gg0GkUvBQA4j8LD/w9/+EPs3LnzVX+mXq9HrVYbctTr9aKXAgB/k0qBRzsa8dj/kUceedXHn3vuudd8jt7e3ujp6RlyrlqtxvE/nB3pcgCgeO2a2gUZcfivWLEiKpVKNJvNV/yZymvcK6lWq1GtVs/zyAsjXQ4AMEIjHvt3d3fHj370ozh37tx5jyNHjozGOgHggqkU+F87GnH4z507Nw4fPvyKj7/WVAAA2l2lUtzRjkY89r/jjjtiYGDgFR9/+9vfHj//+c/f0KIAgNEz4vB///vf/6qPjx8/Pj7wgQ/8zQsCgFZr08JeGB/yAwCpzNPfF/sAQMlo/gCQaNdd+kUR/gCQaNdd+kUR/gCQyDz73fMHgLLR/AEglXn1F/4AkMh9w5+xPwCUjOYPAAm7/QGgZDLPfmN/ACgbzR8AUplXf+EPAAm7/QGArGj+AJCw2x8ASibz7Bf+ADBM5unvnj8AlIzmDwCJ3Hf7C38ASOS+4c/YHwBKRvgDQKJS4DES9Xo95s+fHxMmTIjJkyfHihUr4qmnnirgFQ0l/AEg1aL0/8UvfhFr1qyJX/7yl/HYY4/Fyy+/HB/60IdiYGCgiFc1yD1/AGgTjz766JA/79ixIyZPnhyHDx+OxYsXF3Yd4Q8AiSJ3+zcajWg0GkPOVavVqFarr/n/nj59OiIiJk6cWNh6Ioz9AWCYSqW4o16vR61WG3LU6/XXXMO5c+di/fr1sWjRopg1a1ahr0/zB4BR1NvbGz09PUPOvZ7Wv2bNmvjNb34Tjz/+eOFrEv4AkCjybf6vd8T/f91+++3xk5/8JPbt2xdvectbClzNXwl/AEi16EN+ms1mrF27Nnbt2hV79+6N6dOnj8p1hD8AJFr18b5r1qyJBx98MH784x/HhAkToq+vLyIiarVadHZ2FnYdG/4AoE1s27YtTp8+HR/84Aeju7t78Hj44YcLvY7mDwCJVn22f7PZvCDXEf4AkMj8e32M/QGgbDR/AEhlXv2FPwAkWrXb/0Ix9geAktH8ASDRqt3+F4rwB4BE5tlv7A8AZaP5A0Aq8+ov/AEgkftuf+EPAIncN/y55w8AJaP5A0Ai8+Iv/AEgZewPAGRF8weAYfKu/sIfABLG/gBAVjR/AEhkXvyFPwCkjP0BgKxo/gCQ8Nn+AFA2eWe/8AeAVObZ754/AJSN5g8Aidx3+wt/AEjkvuHP2B8ASkbzB4BU3sVf+ANAKvPsN/YHgLLR/AEgYbc/AJSM3f4AQFY0fwBI5D721/wBoGQ0fwBIaP4AQFY0fwBI5L7bX/gDQMLYHwDIiuYPAInMi7/wB4BhMk9/Y38AKBnNHwASdvsDQMnY7Q8AZEXzB4BE5sVf+APAMJmnv/AHgETuG/7c8weAktH8ASCR+27/SrPZbLZ6EbSPRqMR9Xo9ent7o1qttno50Bb8uyA3wp8h+vv7o1arxenTp+PNb35zq5cDbcG/C3Ljnj8AlIzwB4CSEf4AUDLCnyGq1Wps3LjRpib4P/y7IDc2/AFAyWj+AFAywh8ASkb4A0DJCH8AKBnhz6CtW7fG5ZdfHuPGjYsFCxbEgQMHWr0kaKl9+/bF8uXLY+rUqVGpVGL37t2tXhIUQvgTEREPP/xw9PT0xMaNG+PIkSMxe/bsuPbaa+PkyZOtXhq0zMDAQMyePTu2bt3a6qVAobzVj4iIWLBgQcyfPz+2bNkSERHnzp2Lyy67LNauXRt33nlni1cHrVepVGLXrl2xYsWKVi8F3jDNn/jzn/8chw8fjqVLlw6e6+joiKVLl8b+/ftbuDIARoPwJ06dOhVnz56Nrq6uIee7urqir6+vRasCYLQIfwAoGeFPTJo0KcaMGRMnTpwYcv7EiRMxZcqUFq0KgNEi/ImLLroo5s6dG3v27Bk8d+7cudizZ09cffXVLVwZAKPhTa1eAO2hp6cnVq1aFfPmzYv3vve9sWnTphgYGIjVq1e3emnQMmfOnIlnn3128M/Hjx+PY8eOxcSJE2PatGktXBm8Md7qx6AtW7bEV7/61ejr64urrroqNm/eHAsWLGj1sqBl9u7dG0uWLBl2ftWqVbFjx44LvyAoiPAHgJJxzx8ASkb4A0DJCH8AKBnhDwAlI/wBoGSEPwCUjPAHgJIR/gBQMsIfAEpG+ANAyQh/ACgZ4Q8AJfM/4Iuq5Iw1DnwAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# y_true : vraies classes, y_pred : classes prédites\n",
        "y_true = np.argmax(y_test_ok, axis=1)\n",
        "y_pred = np.argmax(model.predict(x_test_ok), axis=1)\n",
        "\n",
        "# Créer la matrice de confusion\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "sns.heatmap(conf_matrix, cmap='Blues', linewidth=0.5, robust=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
